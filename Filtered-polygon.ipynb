{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "from http.client  import HTTPConnection\n",
    "from urllib.parse import urlencode\n",
    "from arcgis.mapping import create_symbol\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime, date, time\n",
    "\n",
    "#------------------------------------------------------\n",
    "# Runs SPARQL query at SPARQL endpoint and\n",
    "# return results as a Python 'dict' (in the SPARQL1.1 results format)\n",
    "# (for SPARQL1.1 results format refer: https://www.w3.org/TR/sparql11-results-json)\n",
    "#\n",
    "#       sparql_endpoint: 'host:port' ex: '192.168.0.64:7070', 'data.nobelprize.org'\n",
    "#       sparql_query: ex: 'select (count(*) as ?c) {?s?p?o}'\n",
    "#       fmt - optional argument, if specified, returns results in a raw string format\n",
    "#              possiblea values ('csv','json','xml'), any other format will be treated as 'json'\n",
    "#------------------------------------------------------\n",
    "#\n",
    "def run_query(sparql_endpoint,sparql_query,fmt=None):\n",
    "   # create HTTP connection to SPARQL endpoint\n",
    "   conn = HTTPConnection(sparql_endpoint,timeout=100) #may throw HTTPConnection exception\n",
    "   # urlencode query for sending\n",
    "   docbody = urlencode({'query':sparql_query})\n",
    "   # request result in json\n",
    "   hdrs = {'Accept': 'application/sparql-results+json',\n",
    "           'Content-type': 'application/x-www-form-urlencoded'}\n",
    "   raw = False\n",
    "   if fmt is not None:\n",
    "      raw = True\n",
    "      if fmt in ('xml','XML'):\n",
    "         hdrs['Accept'] = 'application/sparql-results+xml'\n",
    "      elif fmt in ('csv','CSV'):\n",
    "         hdrs['Accept'] = 'text/csv, application/sparql-results+csv'\n",
    "\n",
    "   # send post request\n",
    "   conn.request('POST','/sparql',docbody,hdrs) #may throw exception\n",
    "\n",
    "   # read response\n",
    "   resp = conn.getresponse()\n",
    "   if 200 != resp.status:\n",
    "      errmsg = resp.read()\n",
    "      conn.close()\n",
    "      raise Exception('Query Error',errmsg)  # query processing errors - syntax errors, etc.\n",
    "\n",
    "   # content-type header, and actual response data\n",
    "   ctype = resp.getheader('content-type','text/html').lower()\n",
    "   result = resp.read().lstrip()\n",
    "   conn.close()\n",
    "\n",
    "   # check response content-type header\n",
    "   if raw or ctype.find('json') < 0:\n",
    "      return result      # not a SELECT?\n",
    "\n",
    "   # convert result in JSON string into python dict\n",
    "   return json.loads(result)\n",
    "\n",
    "\n",
    "#------------------------------------------------------\n",
    "# Returns pandas DataFrame from the results of running a sparql_query at sparql_endpoint\n",
    "#       sparql_endpoint: 'host:port' ex: '192.168.0.64:7070', 'data.nobelprize.org'\n",
    "#       sparql_query: ex: 'select (count(*) as ?c) {?s?p?o}'\n",
    "#------------------------------------------------------\n",
    "#\n",
    "def create_dataframe(sparql_endpoint,sparql_query):\n",
    "   # run query\n",
    "   result = run_query(sparql_endpoint,sparql_query)  # may throw exception\n",
    "   # result is in SPARQL results format refer: https://www.w3.org/TR/sparql11-results-json/\n",
    "   cols = result.get('head',{}).get('vars',[])\n",
    "   rows = result.get('results',{}).get('bindings',[])\n",
    "\n",
    "   # extract types and columnar data for rows\n",
    "   coltype = {}\n",
    "   nptype = {}\n",
    "   coldata = {}\n",
    "   for col in cols:\n",
    "      coltype[col] = None\n",
    "      coldata[col] = []\n",
    "      nptype[col] = None\n",
    "\n",
    "   # for all rows, save (columnar) data in coldata[] for each col\n",
    "   for row in rows:\n",
    "      for col in cols:\n",
    "         cell = row.get(col,None)\n",
    "         if cell is None:  # unbound value\n",
    "            val = None\n",
    "            if coltype[col] in ('byte','short','int','integer','float','double','decimal'):\n",
    "               val = np.nan #missing numeric values as NaN\n",
    "            coldata[col].append(val)\n",
    "            continue\n",
    "         # compute type and datum\n",
    "         pdval = cell.get('value','')\n",
    "         vtype = cell.get('type','')\n",
    "         langtag = cell.get('xml:lang','')\n",
    "         typeuri = cell.get('datatype','')\n",
    "         pdtype = 'object'\n",
    "         if vtype == 'uri':\n",
    "            pdval = '<'+pdval+'>'\n",
    "         elif langtag != '':\n",
    "            pdval = '\"'+pdval+'\"@'+langtag\n",
    "            coltype[col] = 'object'\n",
    "         elif typeuri != '':\n",
    "            #vtype in ('typed-literal')\n",
    "            typeuri = typeuri.replace('http://www.w3.org/2001/XMLSchema#','')\n",
    "            coltype[col] = typeuri if (coltype[col] is None or coltype[col] == typeuri) else 'object'\n",
    "            pdtype,pdval = typed_value(typeuri,pdval)\n",
    "         nptype[col] = pdtype if (coltype[col] != 'object') else 'object'\n",
    "         coldata[col].append(pdval) # columnar data\n",
    "   # instantiate DataFrame\n",
    "   npdata = {}\n",
    "   for col in cols:\n",
    "      npdata[col] = np.array(coldata[col],dtype=np.dtype(nptype[col]))\n",
    "   return pd.DataFrame(columns=cols,data=npdata)\n",
    "\n",
    "# util: convert literal val into typed-value based on the typeuri\n",
    "def typed_value(typeuri,val):\n",
    "   # {\"duration\", ColTypeDuration},\n",
    "   if typeuri in ('boolean'):\n",
    "      return np.bool, 'true' == val\n",
    "   elif typeuri in ('byte'):\n",
    "      return np.byte, np.int8(val)\n",
    "   elif typeuri in ('short'):\n",
    "      return np.short, np.short(val)\n",
    "   elif typeuri in ('integer','int','nonNegativeInteger'):\n",
    "      return np.intc, np.int(val)\n",
    "   elif typeuri in ('long'):\n",
    "      return np.int_, np.int_(val)\n",
    "   elif typeuri in ('float'):\n",
    "      return np.single, np.float32(val)\n",
    "   elif typeuri in ('double', 'decimal'):\n",
    "      return np.double, np.float64(val)\n",
    "   elif typeuri in ('dateTime'):\n",
    "      return np.datetime64, datetime.fromisoformat(val)\n",
    "   elif typeuri in ('date'):\n",
    "      return pd.date, date.fromisoformat(val)\n",
    "   elif typeuri in ('time'):\n",
    "      return pd.time, time.fromisoformat(val)\n",
    "   return 'object', val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_query = '''PREFIX geo: <http://cambridgesemantics.com/anzograph/geospatial#>\n",
    "                  select ?point_latitude ?point_longitude ?policyID \n",
    "                  from <FLORIDA_INSURANCE_DATASET> \n",
    "                      where{ \n",
    "                          ?policy a <http://florida_insurance/Policy>; \n",
    "                          <policyID> ?policyID; \n",
    "                          <point_latitude> ?point_latitude; \n",
    "                          <point_longitude> ?point_longitude.\n",
    "                        {\n",
    "                          select (geo:agg_polygon(geo:point_xy(?lon, ?lat)) as ?polygon) \n",
    "                          where { \n",
    "                              values (?lon ?lat) {(-82.298984489994 26.837559967283) (-82.18984489994 27.3215816298725) (-82.491432890735 27.6163883241613) (-82.691432890735 27.6215816298725) (-82.691432890735 27.415816298725)} \n",
    "                          }\n",
    "                        }\n",
    "                        filter(geo:is_contains(?polygon, geo:point_xy(?point_longitude, ?point_latitude)))\n",
    "                  }'''\n",
    "\n",
    "polygon_query = '''PREFIX geo: <http://cambridgesemantics.com/anzograph/geospatial#> \n",
    "                    select (geo:as_json(geo:agg_polygon(geo:point_xy(?lon, ?lat))) as ?polygon) \n",
    "                    where { values (?lon ?lat) {(-82.298984489994 26.837559967283) \n",
    "                                                (-82.18984489994 27.3215816298725) \n",
    "                                                (-82.491432890735 27.6163883241613) \n",
    "                                                (-82.691432890735 27.6215816298725) \n",
    "                                                (-82.691432890735 27.415816298725)} }'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "('Query Error', b'Error - FLORIDA_INSURANCE_DATASET: No such graph or view\\n')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-da4a557619e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpointsDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'localhost:7070'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpt_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpolygonDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'localhost:7070'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolygon_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpointsDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-129-b264239b5368>\u001b[0m in \u001b[0;36mcreate_dataframe\u001b[0;34m(sparql_endpoint, sparql_query)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparql_endpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msparql_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m    \u001b[0;31m# run query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m    \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparql_endpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msparql_query\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may throw exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m    \u001b[0;31m# result is in SPARQL results format refer: https://www.w3.org/TR/sparql11-results-json/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m    \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'head'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vars'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-129-b264239b5368>\u001b[0m in \u001b[0;36mrun_query\u001b[0;34m(sparql_endpoint, sparql_query, fmt)\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0merrmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Query Error'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# query processing errors - syntax errors, etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m    \u001b[0;31m# content-type header, and actual response data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: ('Query Error', b'Error - FLORIDA_INSURANCE_DATASET: No such graph or view\\n')"
     ]
    }
   ],
   "source": [
    "pointsDF = create_dataframe('localhost:7070',pt_query)\n",
    "polygonDF = create_dataframe('localhost:7070',polygon_query)\n",
    "pointsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "895b7b54e6d64d6486a5282502800606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MapView(layout=Layout(height='400px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"map-static-img-preview-9e62059d-82bd-4dc5-9717-258ebd309702\"><img src=\"\"></img></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from arcgis.gis import GIS\n",
    "gis = GIS()\n",
    "m = gis.map()\n",
    "\n",
    "symbolPoint = create_symbol(geometry_type='point', colors=[226, 119, 40, 1000], marker_size=10, outline_color=[255, 255, 255, 50])\n",
    "\n",
    "symbolLine = create_symbol(geometry_type='polyline', colors=[226, 119, 40, 100])\n",
    "\n",
    "for i,point in pointsDF.iterrows():\n",
    "    x = {\"y\": point['point_latitude'], \"x\": point['point_longitude']}\n",
    "    m.draw(x, symbol = symbolPoint)\n",
    "    \n",
    "for i, j in polygonDF.iterrows():\n",
    "    y = j[0]\n",
    "\n",
    "from json import loads\n",
    "y = loads(y)\n",
    "\n",
    "m.draw(y, symbol = symbolLine)    \n",
    "m.center = [27.2515816298725, -81.991432890735]\n",
    "m.zoom = 9\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
